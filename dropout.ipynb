{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7697bff8-7d91-43c8-b4fc-bc08920dd171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting triton\n",
      "  Downloading triton-2.0.0.post1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.8/site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.8/site-packages (3.5.3)\n",
      "Collecting lit\n",
      "  Downloading lit-16.0.0.tar.gz (144 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/lib/python3/dist-packages (from triton) (3.0.12)\n",
      "Requirement already satisfied: torch in /usr/lib/python3/dist-packages (from triton) (1.12.1)\n",
      "Collecting cmake\n",
      "  Downloading cmake-3.26.0-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.8/site-packages (from pandas) (2022.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in ./.local/lib/python3.8/site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (7.0.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.8/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib/python3/dist-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "Building wheels for collected packages: lit\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93585 sha256=470926d0b7ba65b880561bf0f0831321653f4088412d35815cac53c73cd3e0d4\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/55/8c/70/227418ffabe16ce98ec58f676aa6f69259bc20811f8d926fcb\n",
      "Successfully built lit\n",
      "Installing collected packages: lit, cmake, triton, tabulate\n",
      "Successfully installed cmake-3.26.0 lit-16.0.0 tabulate-0.9.0 triton-2.0.0.post1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install triton tabulate pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04add3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------  --------  --------  -------  --------  --------  ---------  --------  -------  -------  ---------\n",
      "input      0.398164  -1.14106  1.46103  -1.21333  -1.61976  -0.918388  -1.26812  0.84649  2.82668  -0.473958\n",
      "keep mask  1          1        0         0         1         1          1        0        1         0\n",
      "output     0.796329  -2.28213  0         0        -3.23951  -1.83678   -2.53624  0        5.65337   0\n",
      "---------  --------  --------  -------  --------  --------  ---------  --------  -------  -------  ---------\n"
     ]
    }
   ],
   "source": [
    "import tabulate\n",
    "import torch\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def _dropout(\n",
    "        x_ptr,  # pointer to the input\n",
    "        x_keep_ptr,  # pointer to a mask of 0s and 1s\n",
    "        output_ptr,  # pointer to the output\n",
    "        n_elements,  # number of elements in the `x` tensor\n",
    "        p,  # probability that an element of `x` is changed to zero\n",
    "        BLOCK_SIZE: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    block_start = pid * BLOCK_SIZE\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "    mask = offsets < n_elements\n",
    "    # Load data\n",
    "    x = tl.load(x_ptr + offsets, mask=mask)\n",
    "    x_keep = tl.load(x_keep_ptr + offsets, mask=mask)\n",
    "    # The line below is the crucial part, described in the paragraph above!\n",
    "    output = tl.where(x_keep, x / (1 - p), 0.0)\n",
    "    # Write-back output\n",
    "    tl.store(output_ptr + offsets, output, mask=mask)\n",
    "\n",
    "\n",
    "def dropout(x, x_keep, p):\n",
    "    output = torch.empty_like(x)\n",
    "    assert x.is_contiguous()\n",
    "    n_elements = x.numel()\n",
    "    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
    "    _dropout[grid](x, x_keep, output, n_elements, p, BLOCK_SIZE=1024)\n",
    "    return output\n",
    "\n",
    "\n",
    "# Input tensor\n",
    "x = torch.randn(size=(10,)).cuda()\n",
    "# Dropout mask\n",
    "p = 0.5\n",
    "x_keep = (torch.rand(size=(10,)) > p).to(torch.int32).cuda()\n",
    "#\n",
    "output = dropout(x, x_keep=x_keep, p=p)\n",
    "print(tabulate.tabulate([\n",
    "    [\"input\"] + x.tolist(),\n",
    "    [\"keep mask\"] + x_keep.tolist(),\n",
    "    [\"output\"] + output.tolist()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9451619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------  ---------  -------  --------  --------  ---------  ------  --------  -------  ---------  --------\n",
      "input                -0.151539  1.10336  -1.73476  0.939393  -0.961672  1.0487  -1.82303  2.13982  -0.300116  -1.22286\n",
      "output (seed = 123)   0         2.20672   0        0          0         2.0974   0        0        -0.600231  -2.44572\n",
      "output (seed = 123)   0         2.20672   0        0          0         2.0974   0        0        -0.600231  -2.44572\n",
      "output (seed = 512)   0         0        -3.46951  1.87879    0         2.0974  -3.64605  0         0          0\n",
      "-------------------  ---------  -------  --------  --------  ---------  ------  --------  -------  ---------  --------\n"
     ]
    }
   ],
   "source": [
    "@triton.jit\n",
    "def _seeded_dropout(\n",
    "        x_ptr,\n",
    "        output_ptr,\n",
    "        n_elements,\n",
    "        p,\n",
    "        seed,\n",
    "        BLOCK_SIZE: tl.constexpr,\n",
    "):\n",
    "    # compute memory offsets of elements handled by this instance\n",
    "    pid = tl.program_id(axis=0)\n",
    "    block_start = pid * BLOCK_SIZE\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "    # load data from x\n",
    "    mask = offsets < n_elements\n",
    "    x = tl.load(x_ptr + offsets, mask=mask)\n",
    "    # randomly prune it\n",
    "    random = tl.rand(seed, offsets)\n",
    "    x_keep = random > p\n",
    "    # write-back\n",
    "    output = tl.where(x_keep, x / (1 - p), 0.0)\n",
    "    tl.store(output_ptr + offsets, output, mask=mask)\n",
    "\n",
    "\n",
    "def seeded_dropout(x, p, seed):\n",
    "    output = torch.empty_like(x)\n",
    "    assert x.is_contiguous()\n",
    "    n_elements = x.numel()\n",
    "    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
    "    _seeded_dropout[grid](x, output, n_elements, p, seed, BLOCK_SIZE=1024)\n",
    "    return output\n",
    "\n",
    "\n",
    "x = torch.randn(size=(10,)).cuda()\n",
    "# Compare this to the baseline - dropout mask is never instantiated!\n",
    "output = seeded_dropout(x, p=0.5, seed=123)\n",
    "output2 = seeded_dropout(x, p=0.5, seed=123)\n",
    "output3 = seeded_dropout(x, p=0.5, seed=512)\n",
    "\n",
    "print(tabulate.tabulate([\n",
    "    [\"input\"] + x.tolist(),\n",
    "    [\"output (seed = 123)\"] + output.tolist(),\n",
    "    [\"output (seed = 123)\"] + output2.tolist(),\n",
    "    [\"output (seed = 512)\"] + output3.tolist()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "01d956b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.,  5., 64., 54., 31.,  6., 64.], device='cuda:0')\n",
      "tensor([-2.4132e+18, -2.4139e+18,  6.8079e+18,  6.8090e+18,  6.8095e+18,\n",
      "        -2.4133e+18, -2.4135e+18], device='cuda:0')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "got output2 tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n        [-3.3235,  3.0144,  1.6038, -3.5172]], device='cuda:0') and otuput3 tensor([[-0.5733, -1.2331,  2.1167, -0.6417],\n        [ 0.0000,  0.0000,  0.0000,  0.0000]], device='cuda:0') from x tensor([[-0.2867, -0.6166,  1.0584, -0.3209],\n        [-1.6617,  1.5072,  0.8019, -1.7586]], device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-282-5eb0907c0e84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# TODO: sometimes these two assertions fail and it's unclear why\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"got output2 {output2[0:2, :]} and otuput3 {output3[0:2, :]} from x {x[0:2, :]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: got output2 tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n        [-3.3235,  3.0144,  1.6038, -3.5172]], device='cuda:0') and otuput3 tensor([[-0.5733, -1.2331,  2.1167, -0.6417],\n        [ 0.0000,  0.0000,  0.0000,  0.0000]], device='cuda:0') from x tensor([[-0.2867, -0.6166,  1.0584, -0.3209],\n        [-1.6617,  1.5072,  0.8019, -1.7586]], device='cuda:0')"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Exercise 1: dropout for matrix with vector of seeds, 1 seed per row\n",
    "@triton.jit\n",
    "def _seeded_matrix_dropout(\n",
    "        x_ptr,\n",
    "        output_ptr,\n",
    "        debug_random_mask_ptr,\n",
    "        debug_seeds_ptr,\n",
    "        n_elements,\n",
    "        p,\n",
    "        seeds,\n",
    "        n_elements_per_row: tl.constexpr,\n",
    "        BLOCK_SIZE: tl.constexpr,\n",
    "):\n",
    "    # compute memory offsets of elements handled by this instance\n",
    "    pid = tl.program_id(axis=0)\n",
    "    # index of first row in block.\n",
    "    # e.g. if BLOCK_SIZE is 1024 and this is block 3, then the first row is row 3 * 1024 in the original tensor\n",
    "    start_row_index = pid * BLOCK_SIZE\n",
    "    block_start = start_row_index * n_elements_per_row\n",
    "\n",
    "    # offsets is now a BLOCK_SIZE x n_elements_per_row matrix\n",
    "    row_offsets = (tl.arange(0, BLOCK_SIZE) * n_elements_per_row)[:, None] # left operand is how many rows down we go in current block, right is num elements for that row\n",
    "    col_offsets = tl.arange(0, n_elements_per_row)[None, :]\n",
    "    offsets = block_start + row_offsets + col_offsets\n",
    "\n",
    "    # load data from x\n",
    "    mask = offsets < n_elements\n",
    "    x = tl.load(x_ptr + offsets, mask=mask)\n",
    "    # randomly prune it\n",
    "    random_values = tl.zeros((BLOCK_SIZE, n_elements_per_row), dtype=tl.float32) # one random value per row\n",
    "    for row in range(BLOCK_SIZE):\n",
    "        # note that we get seed from start_row_index + row, NOT row by itself\n",
    "        # we need start_row_index to get the right index into seeds vector.\n",
    "\n",
    "        # random_mask one-hot for current row\n",
    "        # offsets % block_start effectively makes offsets like a matrix [[0, 1, 2, ... n_elements_per_row - 1], [n_elements_per_row, etc]]\n",
    "        # then just accept where offsets / n_elements_per_row == row\n",
    "        random_mask = tl.where(((row_offsets + col_offsets) // n_elements_per_row) == row, 1.0, 0.0)\n",
    "        # Note: the following doesn't work becaues block_start could be 0 for the first block and mod 0 is invalid\n",
    "        # Triton won't error out, it'll just silently give you an invalid result.\n",
    "        # random_mask = tl.where(((offsets % block_start) // n_elements_per_row) == row, 1.0, 0.0)\n",
    "        if row == 1:\n",
    "            tl.store(debug_random_mask_ptr + row_offsets + col_offsets, random_mask, mask=mask)\n",
    "\n",
    "        random_values += (tl.rand(seeds + start_row_index + row, random_values) * random_mask)\n",
    "        # I'm guessing that, because these are all pointers, you probably can't just index into arrays/tensors the way you would in C or python\n",
    "        # That's why we have the pointer arithmetic for random_values instead\n",
    "        # random_values += tl.rand(seeds[start_row_index + row], random_values) * random_mask\n",
    "        seed_value = tl.load(seeds + start_row_index + row)\n",
    "        # seed_value = start_row_index + row\n",
    "        tl.store(debug_seeds_ptr + start_row_index + row, seed_value)\n",
    "    x_keep = random_values > p\n",
    "    # write-back\n",
    "    output = tl.where(x_keep, x / (1 - p), 0.0)\n",
    "    tl.store(output_ptr + offsets, output, mask=mask)\n",
    "\n",
    "\n",
    "def seeded_matrix_dropout(x, p, seeds):\n",
    "    output = torch.empty_like(x)\n",
    "    assert x.is_contiguous()\n",
    "    assert seeds.shape == (x.shape[0],), f\"seeds should be length of num rows but instead got seeds.shape {seeds.shape} and x.shape {x.shape}\"\n",
    "    # raise AssertionError(\"ok\")\n",
    "    n_elements = x.numel()\n",
    "    # print(triton.cdiv(n_elements, 1024))\n",
    "    # print(n_elements)\n",
    "    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),) # for now, treat BLOCK_SIZE as the number of rows per block.\n",
    "    n_elements_per_row = x.shape[1]\n",
    "    debug_random_mask_ptr = torch.zeros((1024, n_elements_per_row)).cuda()\n",
    "    debug_seeds_ptr = torch.zeros(seeds.shape).cuda()\n",
    "    assert seeds.shape == debug_seeds_ptr.shape\n",
    "    _seeded_matrix_dropout[grid](x, output, debug_random_mask_ptr, debug_seeds_ptr, n_elements, p, seeds, n_elements_per_row, BLOCK_SIZE=1024)\n",
    "    return output, debug_random_mask_ptr, debug_seeds_ptr\n",
    "\n",
    "x = torch.randn(size=(1000, 4)).cuda() # n elements per row must be a power of 2\n",
    "# Compare this to the baseline - dropout mask is never instantiated!\n",
    "output1, debug_random_mask_ptr1, debug_seeds_ptr1 = seeded_matrix_dropout(x, p=0.75, seeds=torch.rand(x.shape[0]).cuda())\n",
    "# seeds should match for rows 0 and 1, but not for remaining ones\n",
    "seed2 = torch.cat((torch.tensor([3]), torch.tensor([5]), torch.tensor(np.random.randint(0, 100, size=(x.shape[0]-2))))).cuda()\n",
    "seed3 = torch.cat((torch.tensor([3]), torch.tensor([5]), torch.tensor(np.random.randint(0, 100, size=(x.shape[0]-2))))).cuda()\n",
    "assert not torch.all(torch.eq(seed2, seed3))\n",
    "\n",
    "# Synchronize calls-- wait for all previous cuda code to finish, so pid=0 is ready for each of these seeded_matrix_dropout calls\n",
    "torch.cuda.synchronize()\n",
    "output2, debug_random_mask_ptr2, debug_seeds_ptr2 = seeded_matrix_dropout(x, p=0.5, seeds=seed2)\n",
    "torch.cuda.synchronize()\n",
    "output3, debug_random_mask_ptr3, debug_seeds_ptr3 = seeded_matrix_dropout(x, p=0.5, seeds=seed3)\n",
    "torch.cuda.synchronize()\n",
    "print(debug_seeds_ptr2[0:7])\n",
    "print(debug_seeds_ptr3[0:7])\n",
    "\n",
    "assert torch.all(torch.eq(debug_random_mask_ptr1, debug_random_mask_ptr2))\n",
    "assert torch.all(torch.eq(debug_random_mask_ptr2, debug_random_mask_ptr3))\n",
    "random_mask_should_be = torch.zeros((1024, x.shape[1])).cuda()\n",
    "random_mask_should_be[1, :] = torch.ones(x.shape[1])\n",
    "assert torch.all(torch.eq(random_mask_should_be, debug_random_mask_ptr1)) # check that the random mask is set correctly each time\n",
    "\n",
    "\n",
    "# TODO: sometimes these two assertions fail and it's unclear why\n",
    "assert torch.all(torch.eq(output2[0:2, :], output3[0:2, :])), f\"got output2 {output2[0:2, :]} and otuput3 {output3[0:2, :]} from x {x[0:2, :]}\"\n",
    "print(output2)\n",
    "print(output3)\n",
    "assert not torch.all(torch.eq(output2, output3))\n",
    "# output2\n",
    "# print(\"ok\")\n",
    "\n",
    "# GPT-4 SUGGESTIONS\n",
    "suggest = \"\"\"\n",
    "It seems like the issue is related to the seed values being loaded incorrectly sometimes. One possible reason could be a race condition or synchronization issue in the Triton kernel. To debug this further, you can try the following steps:\n",
    "\n",
    "1. Add more print statements in the Triton kernel to check the values of `start_row_index`, `row`, and `seeds` at different points in the kernel execution. This can help you identify if there's any issue with the indexing or pointer arithmetic.\n",
    "\n",
    "2. Check if there's any issue with the input `seeds` tensor. You can print the `seeds` tensor before passing it to the Triton kernel and compare it with the `debug_seeds_ptr` tensor after the kernel execution.\n",
    "\n",
    "3. Try running the Triton kernel with a smaller block size and see if the issue persists. This can help you identify if the issue is related to the block size or the way the blocks are being scheduled.\n",
    "\n",
    "4. You can also try using Triton's built-in synchronization primitives like `tl.sync` and `tl.syncwarp` to ensure that all threads in a block are synchronized before loading the seed values. This can help you identify if there's any race condition or synchronization issue in the kernel.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "73a60f90-aaad-40ed-82b3-c4a44dc77aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(torch.eq(debug_random_mask_ptr1.cpu(), torch.zeros((1024, x.shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d9274990-5340-4ec8-a689-135afe4451d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(torch.eq(debug_seeds_ptr2.cpu(), torch.arange(1024, 2024, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d64a8f2-722c-4220-ad42-cb216d6c6780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512.5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1025 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b07bf5e1-b00f-4fb0-912e-c5eedd6f2cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef0a36-baf7-480f-a806-b520135d6432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
